{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f281c0961f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchtext import (data, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = data.Field(tokenize = data.get_tokenizer(\"basic_english\"), include_lengths = True)\n",
    "LABEL_FIELD = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_dataset, test_dataset = datasets.IMDB.splits(TEXT_FIELD, LABEL_FIELD)\n",
    "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCABULARY_SIZE = 25000\n",
    "\n",
    "TEXT_FIELD.build_vocab(train_dataset, \n",
    "                 max_size = MAX_VOCABULARY_SIZE)\n",
    "\n",
    "LABEL_FIELD.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_SIZE = 64 # batch size\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data_iterator, valid_data_iterator, test_data_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset, test_dataset), \n",
    "    batch_size = B_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are training using GPUs, we need to use the following function for the pack_padded_sequence method to work \n",
    "## (reference : https://discuss.pytorch.org/t/error-with-lengths-in-pack-padded-sequence/35517/3)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence\n",
    "\n",
    "def cuda_pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=False):\n",
    "    # length becoms a tensor. ref: https://pytorch.org/docs/stable/generated/torch.as_tensor.html\n",
    "    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
    "    lengths = lengths.cpu()\n",
    "    \n",
    "    if enforce_sorted:\n",
    "        sorted_indices = None\n",
    "    else:\n",
    "        # sorted_indices means original position at after sorted tensor.\n",
    "        # ref: https://pytorch.org/docs/stable/generated/torch.sort.html\n",
    "        lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
    "        sorted_indices = sorted_indices.to(input.device)\n",
    "        \n",
    "    batch_dim = 0 if batch_first else 1\n",
    "    input = input.index_select(batch_dim, sorted_indices)\n",
    "\n",
    "    data, batch_sizes = \\\n",
    "    torch._C._VariableFunctions._pack_padded_sequence(input, lengths, batch_first)\n",
    "    return PackedSequence(data, batch_sizes, sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dimension, hidden_dimension, output_dimension, dropout, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension, padding_idx = pad_index)\n",
    "        # num_layers should be > 1. otherwise, it cause below warning\n",
    "        # UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
    "        self.gru_layer = nn.GRU(embedding_dimension, hidden_dimension, num_layers=2,\n",
    "dropout=0.8, bidirectional=True)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension * 2, output_dimension)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, sequence, sequence_lengths=None):\n",
    "        if sequence_lengths is None:\n",
    "            sequence_lengths = torch.LongTensor([len(sequence)])\n",
    "        \n",
    "        # sequence := (sequence_length, batch_size)\n",
    "        embedded_output = self.dropout_layer(self.embedding_layer(sequence))\n",
    "        \n",
    "        \n",
    "        # embedded_output := (sequence_length, batch_size, embedding_dimension)\n",
    "        if torch.cuda.is_available():\n",
    "            packed_embedded_output = cuda_pack_padded_sequence(embedded_output, sequence_lengths)\n",
    "        else:\n",
    "            packed_embedded_output = nn.utils.rnn.pack_padded_sequence(embedded_output, sequence_lengths)\n",
    "        \n",
    "        packed_output, hidden_state = self.gru_layer(packed_embedded_output)\n",
    "        # hidden_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
    "        # num_directions = 2 if bidirectional.\n",
    "        # cell_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
    "        \n",
    "        op, op_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # op := (sequence_length, batch_size, hidden_dimension * num_directions)\n",
    "        \n",
    "        hidden_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)        \n",
    "        # hidden_output := (batch_size, hidden_dimension * num_directions)\n",
    "        \n",
    "        return self.fc_layer(hidden_output)\n",
    "\n",
    "    \n",
    "INPUT_DIMENSION = len(TEXT_FIELD.vocab)\n",
    "EMBEDDING_DIMENSION = 100\n",
    "HIDDEN_DIMENSION = 32\n",
    "OUTPUT_DIMENSION = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.pad_token]\n",
    "\n",
    "gru_model = GRU(INPUT_DIMENSION, \n",
    "            EMBEDDING_DIMENSION, \n",
    "            HIDDEN_DIMENSION, \n",
    "            OUTPUT_DIMENSION, \n",
    "            DROPOUT, \n",
    "            PAD_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.unk_token] # unk means unknown\n",
    "\n",
    "gru_model.embedding_layer.weight.data[UNK_INDEX] = torch.zeros(EMBEDDING_DIMENSION)\n",
    "gru_model.embedding_layer.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(gru_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss() # binary cross entropy.\n",
    "\n",
    "gru_model = gru_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    # round predictions to either 0 or 1\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_iterator, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for curr_batch in data_iterator:\n",
    "        optim.zero_grad()\n",
    "        sequence, sequence_lengths = curr_batch.text\n",
    "        preds = model(sequence, sequence_lengths).squeeze(1)\n",
    "        \n",
    "        loss_curr = loss_func(preds, curr_batch.label)\n",
    "        accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(data_iterator), accuracy/len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_iterator, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for curr_batch in data_iterator:\n",
    "            sequence, sequence_lengths = curr_batch.text\n",
    "            preds = model(sequence, sequence_lengths).squeeze(1)\n",
    "            \n",
    "            loss_curr = loss_func(preds, curr_batch.label)\n",
    "            accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(data_iterator), accuracy/len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time elapsed: 6.839792966842651s\n",
      "training loss: 0.693 | training accuracy: 52.06%\n",
      "validation loss: 0.681 |  validation accuracy: 55.55%\n",
      "\n",
      "epoch number: 2 | time elapsed: 6.554861068725586s\n",
      "training loss: 0.681 | training accuracy: 56.36%\n",
      "validation loss: 0.639 |  validation accuracy: 63.22%\n",
      "\n",
      "epoch number: 3 | time elapsed: 7.345101594924927s\n",
      "training loss: 0.630 | training accuracy: 64.17%\n",
      "validation loss: 0.582 |  validation accuracy: 72.86%\n",
      "\n",
      "epoch number: 4 | time elapsed: 6.76948881149292s\n",
      "training loss: 0.566 | training accuracy: 70.51%\n",
      "validation loss: 0.471 |  validation accuracy: 79.24%\n",
      "\n",
      "epoch number: 5 | time elapsed: 6.931855916976929s\n",
      "training loss: 0.498 | training accuracy: 76.58%\n",
      "validation loss: 0.454 |  validation accuracy: 79.50%\n",
      "\n",
      "epoch number: 6 | time elapsed: 7.400043964385986s\n",
      "training loss: 0.449 | training accuracy: 79.26%\n",
      "validation loss: 0.432 |  validation accuracy: 82.65%\n",
      "\n",
      "epoch number: 7 | time elapsed: 7.300610065460205s\n",
      "training loss: 0.415 | training accuracy: 81.52%\n",
      "validation loss: 0.596 |  validation accuracy: 75.84%\n",
      "\n",
      "epoch number: 8 | time elapsed: 7.209696531295776s\n",
      "training loss: 0.365 | training accuracy: 84.42%\n",
      "validation loss: 0.538 |  validation accuracy: 79.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(gru_model, train_data_iterator, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(gru_model, valid_data_iterator, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(gru_model.state_dict(), 'gru_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.load_state_dict(torch.load('../../Mastering-PyTorch/Chapter04/gru_model.pt'))\n",
    "\n",
    "test_loss, test_accuracy = validate(gru_model, test_data_iterator, loss_func)\n",
    "\n",
    "print(f'test loss: {test_loss:.3f} | test accuracy: {test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # text transformations\n",
    "    tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
    "    tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    \n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sentiment_inference(gru_model, \"This film is horrible\"))\n",
    "print(sentiment_inference(gru_model, \"Director tried too hard but this film is bad\"))\n",
    "print(sentiment_inference(gru_model, \"Decent movie, although could be shorter\"))\n",
    "print(sentiment_inference(gru_model, \"This film will be houseful for weeks\"))\n",
    "print(sentiment_inference(gru_model, \"I loved the movie, every part of it\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
