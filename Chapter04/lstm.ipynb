{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM \n",
    "# explanation:  http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9be4ba91f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchtext import (data, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = data.Field(tokenize = data.get_tokenizer(\"basic_english\"), include_lengths = True)\n",
    "LABEL_FIELD = data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_dataset, test_dataset = datasets.IMDB.splits(TEXT_FIELD, LABEL_FIELD)\n",
    "train_dataset, valid_dataset = train_dataset.split(random_state = random.seed(123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCABULARY_SIZE = 25000\n",
    "\n",
    "TEXT_FIELD.build_vocab(train_dataset, \n",
    "                 max_size = MAX_VOCABULARY_SIZE)\n",
    "\n",
    "LABEL_FIELD.build_vocab(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_SIZE = 64 # batch size\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data_iterator, valid_data_iterator, test_data_iterator = data.BucketIterator.splits(\n",
    "    (train_dataset, valid_dataset, test_dataset), \n",
    "    batch_size = B_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are training using GPUs, we need to use the following function for the pack_padded_sequence method to work \n",
    "## (reference : https://discuss.pytorch.org/t/error-with-lengths-in-pack-padded-sequence/35517/3)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, PackedSequence\n",
    "\n",
    "def cuda_pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=False):\n",
    "    # length becoms a tensor. ref: https://pytorch.org/docs/stable/generated/torch.as_tensor.html\n",
    "    lengths = torch.as_tensor(lengths, dtype=torch.int64)\n",
    "    lengths = lengths.cpu()\n",
    "    \n",
    "    if enforce_sorted:\n",
    "        sorted_indices = None\n",
    "    else:\n",
    "        # sorted_indices means original position at after sorted tensor.\n",
    "        # ref: https://pytorch.org/docs/stable/generated/torch.sort.html\n",
    "        lengths, sorted_indices = torch.sort(lengths, descending=True)\n",
    "        sorted_indices = sorted_indices.to(input.device)\n",
    "        \n",
    "    batch_dim = 0 if batch_first else 1\n",
    "    input = input.index_select(batch_dim, sorted_indices)\n",
    "\n",
    "    data, batch_sizes = \\\n",
    "    torch._C._VariableFunctions._pack_padded_sequence(input, lengths, batch_first)\n",
    "    return PackedSequence(data, batch_sizes, sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_dimension, hidden_dimension, output_dimension, dropout, pad_index):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension, padding_idx = pad_index)\n",
    "        # num_layers should be > 1. otherwise, it cause below warning\n",
    "        # UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
    "        self.lstm_layer = nn.LSTM(embedding_dimension, \n",
    "                           hidden_dimension, \n",
    "                           num_layers=2, \n",
    "                           bidirectional=True, \n",
    "                           dropout=dropout)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension * 2, output_dimension)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, sequence, sequence_lengths=None):\n",
    "        if sequence_lengths is None:\n",
    "            sequence_lengths = torch.LongTensor([len(sequence)])\n",
    "        \n",
    "        # sequence := (sequence_length, batch_size)\n",
    "        embedded_output = self.dropout_layer(self.embedding_layer(sequence))\n",
    "        \n",
    "        \n",
    "        # embedded_output := (sequence_length, batch_size, embedding_dimension)\n",
    "        if torch.cuda.is_available():\n",
    "            packed_embedded_output = cuda_pack_padded_sequence(embedded_output, sequence_lengths)\n",
    "        else:\n",
    "            packed_embedded_output = nn.utils.rnn.pack_padded_sequence(embedded_output, sequence_lengths)\n",
    "        \n",
    "        packed_output, (hidden_state, cell_state) = self.lstm_layer(packed_embedded_output)\n",
    "        # hidden_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
    "        # num_directions = 2 if bidirectional LSTM.\n",
    "        # cell_state := (num_layers * num_directions, batch_size, hidden_dimension)\n",
    "        \n",
    "        op, op_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "        # op := (sequence_length, batch_size, hidden_dimension * num_directions)\n",
    "        \n",
    "        hidden_output = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)        \n",
    "        # hidden_output := (batch_size, hidden_dimension * num_directions)\n",
    "        \n",
    "        return self.fc_layer(hidden_output)\n",
    "\n",
    "    \n",
    "INPUT_DIMENSION = len(TEXT_FIELD.vocab)\n",
    "EMBEDDING_DIMENSION = 100\n",
    "HIDDEN_DIMENSION = 32\n",
    "OUTPUT_DIMENSION = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.pad_token]\n",
    "\n",
    "lstm_model = LSTM(INPUT_DIMENSION, \n",
    "            EMBEDDING_DIMENSION, \n",
    "            HIDDEN_DIMENSION, \n",
    "            OUTPUT_DIMENSION, \n",
    "            DROPOUT, \n",
    "            PAD_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_INDEX = TEXT_FIELD.vocab.stoi[TEXT_FIELD.unk_token] # unk means unknown\n",
    "\n",
    "lstm_model.embedding_layer.weight.data[UNK_INDEX] = torch.zeros(EMBEDDING_DIMENSION)\n",
    "lstm_model.embedding_layer.weight.data[PAD_INDEX] = torch.zeros(EMBEDDING_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(lstm_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss() # binary cross entropy.\n",
    "\n",
    "lstm_model = lstm_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    # round predictions to either 0 or 1\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_iterator, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for curr_batch in data_iterator:\n",
    "        optim.zero_grad()\n",
    "        sequence, sequence_lengths = curr_batch.text\n",
    "        preds = lstm_model(sequence, sequence_lengths).squeeze(1)\n",
    "        \n",
    "        loss_curr = loss_func(preds, curr_batch.label)\n",
    "        accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(data_iterator), accuracy/len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_iterator, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for curr_batch in data_iterator:\n",
    "            sequence, sequence_lengths = curr_batch.text\n",
    "            preds = model(sequence, sequence_lengths).squeeze(1)\n",
    "            \n",
    "            loss_curr = loss_func(preds, curr_batch.label)\n",
    "            accuracy_curr = accuracy_metric(preds, curr_batch.label)\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(data_iterator), accuracy/len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time elapsed: 7.216773271560669s\n",
      "training loss: 0.683 | training accuracy: 55.51%\n",
      "validation loss: 0.632 |  validation accuracy: 65.00%\n",
      "\n",
      "epoch number: 2 | time elapsed: 7.319506645202637s\n",
      "training loss: 0.607 | training accuracy: 67.18%\n",
      "validation loss: 0.513 |  validation accuracy: 74.96%\n",
      "\n",
      "epoch number: 3 | time elapsed: 7.346320629119873s\n",
      "training loss: 0.538 | training accuracy: 73.13%\n",
      "validation loss: 0.475 |  validation accuracy: 77.69%\n",
      "\n",
      "epoch number: 4 | time elapsed: 7.020611524581909s\n",
      "training loss: 0.504 | training accuracy: 75.76%\n",
      "validation loss: 0.426 |  validation accuracy: 80.49%\n",
      "\n",
      "epoch number: 5 | time elapsed: 7.159215688705444s\n",
      "training loss: 0.450 | training accuracy: 79.33%\n",
      "validation loss: 0.382 |  validation accuracy: 84.11%\n",
      "\n",
      "epoch number: 6 | time elapsed: 7.411106586456299s\n",
      "training loss: 0.477 | training accuracy: 77.29%\n",
      "validation loss: 0.558 |  validation accuracy: 71.92%\n",
      "\n",
      "epoch number: 7 | time elapsed: 7.131444215774536s\n",
      "training loss: 0.481 | training accuracy: 77.39%\n",
      "validation loss: 0.489 |  validation accuracy: 78.20%\n",
      "\n",
      "epoch number: 8 | time elapsed: 7.444781541824341s\n",
      "training loss: 0.419 | training accuracy: 81.31%\n",
      "validation loss: 0.390 |  validation accuracy: 83.01%\n",
      "\n",
      "epoch number: 9 | time elapsed: 7.302513122558594s\n",
      "training loss: 0.418 | training accuracy: 81.16%\n",
      "validation loss: 0.385 |  validation accuracy: 82.94%\n",
      "\n",
      "epoch number: 10 | time elapsed: 7.147495746612549s\n",
      "training loss: 0.400 | training accuracy: 82.38%\n",
      "validation loss: 0.416 |  validation accuracy: 81.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(lstm_model, train_data_iterator, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(lstm_model, valid_data_iterator, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(lstm_model.state_dict(), 'lstm_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.401 | test accuracy: 82.86%\n"
     ]
    }
   ],
   "source": [
    "lstm_model.load_state_dict(torch.load('../../Mastering-PyTorch/Chapter04/lstm_model.pt'))\n",
    "\n",
    "test_loss, test_accuracy = validate(lstm_model, test_data_iterator, loss_func)\n",
    "\n",
    "print(f'test loss: {test_loss:.3f} | test accuracy: {test_accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval()\n",
    "    \n",
    "    # text transformations\n",
    "    tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
    "    tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    \n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2899036407470703\n",
      "0.04821621999144554\n",
      "0.4011892080307007\n",
      "0.5961778163909912\n",
      "0.8934914469718933\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(lstm_model, \"This film is horrible\"))\n",
    "print(sentiment_inference(lstm_model, \"Director tried too hard but this film is bad\"))\n",
    "print(sentiment_inference(lstm_model, \"Decent movie, although could be shorter\"))\n",
    "print(sentiment_inference(lstm_model, \"This film will be houseful for weeks\"))\n",
    "print(sentiment_inference(lstm_model, \"I loved the movie, every part of it\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization ??\n",
    "### but doesn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.3.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (58.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.26.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.8)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.2)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/data/anaconda3/envs/study/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "! python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(lstm_model, lstm_model.embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_sigmoid(input, l):\n",
    "    return torch.sigmoid(lstm_model(input, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "\n",
    "def interpret_sentence(model, sentence, min_len = 7, label = 0):\n",
    "    # text transformations\n",
    "    tokenized = data.get_tokenizer(\"basic_english\")(sentence)\n",
    "    tokenized = [TEXT_FIELD.vocab.stoi[t] for t in tokenized]\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device)\n",
    "    model_input = model_input.unsqueeze(1)\n",
    "    length_input = torch.LongTensor([len(tokenized)])\n",
    "    pred = torch.sigmoid(model(model_input, length_input))\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(len(tokenized), device=device).unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    print(model_input.shape)\n",
    "    print(reference_indices)\n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(model_input,\n",
    "                                           reference_indices.reshape(model_input.shape[1], model_input.shape[0]), \n",
    "                                           n_steps=500, return_convergence_delta=True)\n",
    "\n",
    "    print('pred: ', Label.vocab.itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "    \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            Label.vocab.itos[pred_ind],\n",
    "                            Label.vocab.itos[label],\n",
    "                            Label.vocab.itos[1],\n",
    "                            attributions.sum(),       \n",
    "                            text,\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])\n",
      "tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Baseline can be provided as a tensor for just one input and broadcasted to the batch or input and baseline must have the same shape or the baseline corresponding to each input tensor must be a scalar. Found baseline: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0') and input: tensor([[[ 1.5899e-01,  3.9581e-01,  8.3462e-01,  9.0878e-01, -1.8682e-02,\n           1.2946e+00,  4.9903e-01, -3.9060e-01,  1.2779e+00, -1.1718e+00,\n           2.2578e-01, -2.1784e+00, -8.9297e-01,  2.3828e-01,  1.0838e+00,\n           3.1132e-02,  5.1392e-01,  7.9335e-01,  1.2815e-01, -8.2359e-01,\n           1.0550e+00,  2.1603e-01, -7.1140e-01,  2.1493e-03, -8.0563e-01,\n           7.3644e-01,  8.6861e-01,  3.3154e-01, -2.3092e+00, -1.0909e+00,\n           5.0913e-01,  8.7766e-01, -6.7373e-01,  1.3036e+00, -3.6899e-01,\n          -8.1205e-01, -5.6677e-01, -7.9048e-01,  6.9638e-01, -2.2907e-01,\n          -2.7089e+00, -3.4715e-01,  1.0964e+00, -4.3381e-01, -6.3328e-01,\n           1.1284e+00,  8.4442e-01,  7.3844e-01,  2.5823e-02,  2.0916e+00,\n           5.5208e-02, -5.9757e-01, -8.5522e-01,  1.1001e+00,  6.4866e-01,\n           3.9835e-01, -1.6432e+00, -1.0061e+00,  5.0756e-01, -9.1122e-01,\n           1.6324e-01,  1.4564e+00, -3.8453e-01, -1.7927e-01,  1.9327e-01,\n          -1.0681e+00, -5.3395e-01,  1.0046e+00,  1.0359e+00,  6.3755e-01,\n          -1.2106e+00,  1.0613e+00, -1.7825e+00,  9.5887e-01, -1.0199e+00,\n           9.5073e-01,  9.9059e-01, -4.8548e-01,  5.1139e-01, -9.8376e-01,\n           7.3883e-01,  7.8875e-01,  7.1675e-01,  4.7122e-01,  1.4556e+00,\n           6.9142e-01,  2.3638e-01,  8.7639e-02,  1.5929e-01, -3.0165e-01,\n          -5.9262e-01,  7.9961e-01,  6.3470e-01, -5.0957e-01, -1.3268e-01,\n           4.5197e-01,  5.7480e-01, -1.2900e+00, -1.4176e+00,  2.2525e+00]],\n\n        [[-6.0990e-01, -7.1162e-03, -3.5230e-01, -7.1586e-01, -6.4691e-01,\n          -5.3946e-01,  4.3544e-01, -1.1125e+00, -1.7052e+00,  1.4048e-02,\n           8.4729e-01, -1.4919e+00, -2.3127e-01, -1.4540e+00,  4.7199e-01,\n           4.3575e-01, -1.1604e+00,  1.7407e+00,  1.4828e-01,  2.5753e+00,\n          -3.9196e-01,  1.5379e+00, -9.2076e-01, -2.8512e-01,  8.2832e-01,\n           7.7631e-01, -9.2027e-01,  1.2276e+00, -1.0036e+00,  3.4194e-01,\n           9.5555e-01, -1.2601e+00,  5.1857e-01, -2.9635e-01, -1.0057e+00,\n           1.4105e+00, -5.4511e-01, -7.8574e-01,  2.2185e-01, -1.5449e+00,\n           1.4163e+00, -1.9123e+00, -5.9268e-01, -9.6424e-03,  1.1232e+00,\n          -7.1503e-01,  1.2369e+00, -3.5510e-01, -2.4510e+00,  2.3202e+00,\n           4.4226e-01, -1.4638e+00,  4.7718e-02,  3.7105e-01,  8.7604e-01,\n          -1.2044e+00,  7.1035e-01, -1.3140e+00, -2.0518e-01,  1.3727e-01,\n          -1.6167e+00,  2.5406e-01, -7.8117e-01, -3.7308e-01, -7.0169e-01,\n           8.6800e-01, -9.4508e-01, -1.1207e-01, -6.8230e-01,  1.8243e+00,\n           2.0093e-01, -6.9027e-01, -1.0147e+00,  1.1779e+00, -2.2387e+00,\n          -2.6378e+00, -2.8828e-01,  3.3515e-01,  8.3937e-01,  6.2541e-01,\n          -8.6416e-01,  4.7975e-01,  9.8031e-01,  1.1215e+00, -9.3458e-01,\n          -1.5531e-01,  1.4716e+00, -4.0777e-01,  4.4154e-02, -6.4398e-01,\n           9.0853e-02, -3.6660e-01,  4.7068e-01, -9.0916e-01,  5.7365e-02,\n          -1.4034e+00,  3.3440e-01,  1.4931e-01, -1.3336e+00, -1.0846e-02]],\n\n        [[-9.5110e-01, -7.0620e-03,  1.4664e+00, -7.2822e-02,  1.6167e+00,\n           2.0529e-01,  2.0434e+00,  6.3391e-01, -6.7473e-01, -1.4003e+00,\n           1.4847e+00, -1.1046e-01,  8.9979e-01, -1.9165e+00, -4.4945e-01,\n          -2.9848e-01, -1.5685e+00,  4.3572e-01,  1.4080e-01, -1.3210e+00,\n          -7.1064e-01,  5.6128e-01,  8.8877e-01,  9.6616e-01, -7.2182e-01,\n           1.5497e+00,  1.2478e+00, -2.7926e-01,  2.3774e+00,  4.6843e-01,\n           8.2842e-01, -5.0900e-01,  4.3904e-01,  9.3011e-03,  5.6372e-01,\n          -6.7623e-01, -1.3174e+00, -3.3618e-01, -8.5175e-01,  1.7084e+00,\n           3.9251e-01,  6.1506e-01,  1.6341e+00, -2.7244e-02,  1.0603e+00,\n           6.2143e-01,  1.8539e+00,  8.0723e-01,  7.0309e-01,  6.7047e-01,\n           2.0411e-01, -5.3258e-01, -1.4166e+00,  6.0213e-01, -1.0231e+00,\n          -1.7525e+00,  2.0353e+00, -5.4666e-01,  1.4422e+00, -3.2823e-01,\n          -1.1709e+00,  8.1312e-01,  3.5337e-01, -8.8316e-01, -1.2471e+00,\n          -1.9352e-01,  5.1235e-01, -8.0290e-01, -6.0411e-01,  4.7489e-02,\n          -3.0681e-01, -8.0887e-01, -1.2147e+00,  1.2481e+00, -1.6954e+00,\n           1.7670e-01, -6.9225e-01,  7.1540e-02,  2.0898e+00,  1.1484e-01,\n          -8.2643e-01,  8.3625e-02,  1.1815e+00, -4.9900e-01,  9.8698e-02,\n          -7.1430e-01,  1.7285e+00,  1.4402e+00, -3.2650e-03, -1.4089e-01,\n          -1.3567e+00, -9.2281e-02,  3.2848e-01, -1.7771e-01, -2.0604e-01,\n           1.4197e+00, -4.3751e-01, -3.2615e-01,  6.2895e-01,  5.3981e-01]],\n\n        [[ 1.6892e+00, -1.9431e-01, -3.2224e-01,  3.4490e-01, -1.1653e+00,\n          -3.9481e-01, -3.5266e-01,  5.9497e-01,  2.1040e+00, -1.6459e+00,\n          -9.0557e-01, -1.1838e+00, -6.3269e-01, -9.6686e-01, -1.1722e+00,\n           5.4055e-01, -2.9333e-01,  1.9952e+00, -1.3771e-01,  2.9921e+00,\n          -6.5558e-01, -9.3074e-01, -2.2860e-01, -2.2551e-02,  9.0229e-01,\n          -2.0580e-03, -7.8316e-01, -8.9419e-01, -2.2447e-01, -1.8828e+00,\n           1.0121e+00,  1.3446e+00, -4.9502e-01, -3.0010e-01, -5.9109e-01,\n          -1.4185e-01,  5.4657e-02, -6.8540e-01,  6.5147e-02,  2.9379e+00,\n          -4.9744e-01, -1.7516e+00, -2.7392e-01,  1.7361e+00,  2.5768e-01,\n           8.0858e-01, -7.7159e-01, -1.6262e+00, -1.6733e+00, -2.0280e-01,\n          -4.3399e-01,  2.9403e-01,  4.1337e-01,  1.4134e+00,  1.7226e+00,\n          -8.6325e-01,  1.0139e+00,  1.3789e-01, -1.9410e-01,  5.0410e-01,\n          -9.0640e-01, -1.4849e+00,  4.1672e-02, -1.7339e-01,  7.6474e-01,\n          -6.8545e-01, -8.4875e-01, -6.3901e-01, -1.9897e+00,  9.4109e-02,\n          -1.0168e+00, -8.8822e-01,  3.0812e-02,  5.4795e-01, -5.3808e-01,\n           3.4739e-01,  1.3666e+00, -7.9314e-02, -5.8982e-03,  8.4411e-01,\n           1.1872e-01, -1.1269e+00, -2.4777e+00,  1.0928e+00,  2.2439e+00,\n          -5.6637e-01,  4.0842e-01, -1.0176e+00,  1.6326e+00, -1.7560e-01,\n           1.1970e-01,  7.9557e-02,  4.5318e-01,  1.2080e+00,  1.6906e+00,\n          -3.1913e+00,  6.5363e-01,  1.0044e+00,  6.5124e-01, -4.6142e-01]],\n\n        [[ 1.1474e+00, -1.2219e+00,  1.5311e+00, -1.9181e+00,  1.0266e+00,\n          -1.0445e+00, -1.5458e-01, -8.7398e-01, -3.9716e-01,  1.2200e+00,\n           5.9102e-01, -2.0237e-01,  2.6036e-01,  2.8829e-01, -6.0330e-01,\n          -2.4380e+00, -1.6508e+00,  6.3733e-01, -8.7281e-01,  9.6396e-01,\n           3.6009e-02,  4.7853e-01,  5.8551e-01, -1.0222e+00,  4.6850e-01,\n           8.5582e-01,  2.3504e-01,  4.0865e-02,  5.8716e-01, -1.5681e+00,\n           1.2935e+00, -2.1845e-01, -2.3343e-02,  5.1217e-01, -1.4539e+00,\n          -1.0669e-01, -1.1420e+00,  7.4076e-01, -6.0516e-01,  9.7153e-01,\n          -1.7203e+00,  1.6090e-01,  7.2770e-01,  1.3474e-01, -2.3276e-01,\n          -9.8349e-01,  8.7394e-01,  1.6044e+00,  2.2305e+00,  1.3159e+00,\n           1.2003e+00,  6.3528e-01,  4.0749e-01,  1.7186e+00,  9.2511e-01,\n          -6.4882e-01, -2.2362e+00, -1.8320e+00,  2.0051e+00,  7.4933e-01,\n          -4.9061e-02, -4.2367e-01, -2.9759e-01, -5.2820e-01, -1.0170e+00,\n           1.9610e+00, -7.1650e-01,  1.2064e+00, -1.3965e+00,  8.5272e-01,\n          -1.1305e+00,  4.8074e-01,  6.8236e-01, -2.9311e-02,  1.4540e+00,\n          -2.0741e+00, -1.4512e+00,  5.4786e-01, -3.1652e-01,  6.1505e-01,\n           8.1605e-01, -3.6835e-01,  1.6427e-01, -1.1652e+00,  5.2819e-01,\n          -9.3690e-01, -1.0042e+00,  2.5815e-01, -2.2093e-01,  1.0568e+00,\n           1.8710e-01, -1.6438e+00, -1.0410e+00, -1.6262e-01,  2.7776e-01,\n          -1.2441e+00,  7.0846e-01, -1.2571e+00, -1.9005e+00, -5.5108e-01]],\n\n        [[-6.2225e-01,  1.1263e-01,  1.5201e+00,  1.6294e+00,  6.9333e-01,\n           1.4749e+00,  4.0515e-01,  1.3435e+00, -1.6834e+00, -1.9123e-01,\n          -2.9999e-01, -1.7239e+00,  3.9591e-01, -1.3796e+00,  1.8547e+00,\n          -1.6333e+00,  1.7782e+00,  2.2036e-01, -1.0546e+00, -3.7253e-01,\n           2.2099e+00, -1.9922e-01, -1.1540e+00,  1.2550e+00, -1.5669e+00,\n          -5.9739e-01, -8.7843e-01,  1.5402e+00,  7.8677e-01,  2.5974e+00,\n           1.7088e+00,  3.4667e-01, -1.3186e+00, -8.7469e-01,  2.6160e+00,\n           1.1151e+00, -2.2571e-01, -5.5196e-01, -3.2358e-01,  6.2215e-02,\n          -5.6477e-01, -9.4670e-01,  9.1513e-03, -1.6173e+00,  4.9922e-01,\n          -1.4955e+00, -9.5343e-01, -1.1535e+00,  3.5272e-01,  6.0270e-01,\n          -3.2133e-01, -5.4476e-01,  1.2251e+00, -1.2561e+00,  1.1752e+00,\n          -8.2474e-01,  6.7103e-01, -1.1552e-01, -8.4066e-01,  1.2818e+00,\n           1.4465e+00,  5.5877e-01,  6.8670e-01, -2.1592e-01, -1.2302e+00,\n          -1.3102e+00,  5.6326e-01,  3.2067e-01, -1.4668e+00,  6.4914e-01,\n           8.9192e-01,  1.1502e+00, -6.2337e-02, -8.9526e-01,  7.5140e-01,\n           9.3156e-01,  8.2075e-01, -2.6678e-01, -1.6224e+00,  1.0034e+00,\n           5.8191e-01, -6.9103e-01, -3.7767e-01,  7.8173e-01, -1.1547e+00,\n           5.6047e-02, -5.8822e-01,  5.8918e-01, -7.3669e-01, -1.3374e+00,\n          -5.9425e-01,  6.1755e-01,  6.9365e-01,  1.0297e+00,  9.5625e-01,\n          -2.8796e-01,  1.7674e-01, -3.5438e-01, -1.3552e+00, -4.5781e-01]]],\n       device='cuda:0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13460/2447905405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'It was a fantastic performance !'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Best film ever'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Such a great show!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'It was a horrible movie'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'I\\'ve never watched something as bad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13460/597509037.py\u001b[0m in \u001b[0;36minterpret_sentence\u001b[0;34m(model, sentence, min_len, label)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# compute attributions and approximation delta using layer integrated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     attributions_ig, delta = lig.attribute(model_input,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                            \u001b[0mreference_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                            n_steps=500, return_convergence_delta=True)\n",
      "\u001b[0;32m~/anaconda3/envs/study/lib/python3.9/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study/lib/python3.9/site-packages/captum/attr/_core/layer/layer_integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[1;32m    486\u001b[0m         )\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         attributions = self.ig.attribute.__wrapped__(  # type: ignore\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0minputs_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_input_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minternal_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study/lib/python3.9/site-packages/captum/attr/_utils/common.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(inputs, baselines, n_steps, method, draw_baseline_from_distrib)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdraw_baseline_from_distrib\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m ) -> None:\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0m_validate_input_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_baseline_from_distrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     assert (\n\u001b[1;32m     47\u001b[0m         \u001b[0mn_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/study/lib/python3.9/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(inputs, baselines, draw_baseline_from_distrib)\u001b[0m\n\u001b[1;32m     95\u001b[0m             )\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             assert (\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Baseline can be provided as a tensor for just one input and broadcasted to the batch or input and baseline must have the same shape or the baseline corresponding to each input tensor must be a scalar. Found baseline: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]],\n\n        [[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0') and input: tensor([[[ 1.5899e-01,  3.9581e-01,  8.3462e-01,  9.0878e-01, -1.8682e-02,\n           1.2946e+00,  4.9903e-01, -3.9060e-01,  1.2779e+00, -1.1718e+00,\n           2.2578e-01, -2.1784e+00, -8.9297e-01,  2.3828e-01,  1.0838e+00,\n           3.1132e-02,  5.1392e-01,  7.9335e-01,  1.2815e-01, -8.2359e-01,\n           1.0550e+00,  2.1603e-01, -7.1140e-01,  2.1493e-03, -8.0563e-01,\n           7.3644e-01,  8.6861e-01,  3.3154e-01, -2.3092e+00, -1.0909e+00,\n           5.0913e-01,  8.7766e-01, -6.7373e-01,  1.3036e+00, -3.6899e-01,\n          -8.1205e-01, -5.6677e-01, -7.9048e-01,  6.9638e-01, -2.2907e-01,\n          -2.7089e+00, -3.4715e-01,  1.0964e+00, -4.3381e-01, -6.3328e-01,\n           1.1284e+00,  8.4442e-01,  7.3844e-01,  2.5823e-02,  2.0916e+00,\n           5.5208e-02, -5.9757e-01, -8.5522e-01,  1.1001e+00,  6.4866e-01,\n           3.9835e-01, -1.6432e+00, -1.0061e+00,  5.0756e-01, -9.1122e-01,\n           1.6324e-01,  1.4564e+00, -3.8453e-01, -1.7927e-01,  1.9327e-01,\n          -1.0681e+00, -5.3395e-01,  1.0046e+00,  1.0359e+00,  6.3755e-01,\n          -1.2106e+00,  1.0613e+00, -1.7825e+00,  9.5887e-01, -1.0199e+00,\n           9.5073e-01,  9.9059e-01, -4.8548e-01,  5.1139e-01, -9.8376e-01,\n           7.3883e-01,  7.8875e-01,  7.1675e-01,  4.7122e-01,  1.4556e+00,\n           6.9142e-01,  2.3638e-01,  8.7639e-02,  1.5929e-01, -3.0165e-01,\n          -5.9262e-01,  7.9961e-01,  6.3470e-01, -5.0957e-01, -1.3268e-01,\n           4.5197e-01,  5.7480e-01, -1.2900e+00, -1.4176e+00,  2.2525e+00]],\n\n        [[-6.0990e-01, -7.1162e-03, -3.5230e-01, -7.1586e-01, -6.4691e-01,\n          -5.3946e-01,  4.3544e-01, -1.1125e+00, -1.7052e+00,  1.4048e-02,\n           8.4729e-01, -1.4919e+00, -2.3127e-01, -1.4540e+00,  4.7199e-01,\n           4.3575e-01, -1.1604e+00,  1.7407e+00,  1.4828e-01,  2.5753e+00,\n          -3.9196e-01,  1.5379e+00, -9.2076e-01, -2.8512e-01,  8.2832e-01,\n           7.7631e-01, -9.2027e-01,  1.2276e+00, -1.0036e+00,  3.4194e-01,\n           9.5555e-01, -1.2601e+00,  5.1857e-01, -2.9635e-01, -1.0057e+00,\n           1.4105e+00, -5.4511e-01, -7.8574e-01,  2.2185e-01, -1.5449e+00,\n           1.4163e+00, -1.9123e+00, -5.9268e-01, -9.6424e-03,  1.1232e+00,\n          -7.1503e-01,  1.2369e+00, -3.5510e-01, -2.4510e+00,  2.3202e+00,\n           4.4226e-01, -1.4638e+00,  4.7718e-02,  3.7105e-01,  8.7604e-01,\n          -1.2044e+00,  7.1035e-01, -1.3140e+00, -2.0518e-01,  1.3727e-01,\n          -1.6167e+00,  2.5406e-01, -7.8117e-01, -3.7308e-01, -7.0169e-01,\n           8.6800e-01, -9.4508e-01, -1.1207e-01, -6.8230e-01,  1.8243e+00,\n           2.0093e-01, -6.9027e-01, -1.0147e+00,  1.1779e+00, -2.2387e+00,\n          -2.6378e+00, -2.8828e-01,  3.3515e-01,  8.3937e-01,  6.2541e-01,\n          -8.6416e-01,  4.7975e-01,  9.8031e-01,  1.1215e+00, -9.3458e-01,\n          -1.5531e-01,  1.4716e+00, -4.0777e-01,  4.4154e-02, -6.4398e-01,\n           9.0853e-02, -3.6660e-01,  4.7068e-01, -9.0916e-01,  5.7365e-02,\n          -1.4034e+00,  3.3440e-01,  1.4931e-01, -1.3336e+00, -1.0846e-02]],\n\n        [[-9.5110e-01, -7.0620e-03,  1.4664e+00, -7.2822e-02,  1.6167e+00,\n           2.0529e-01,  2.0434e+00,  6.3391e-01, -6.7473e-01, -1.4003e+00,\n           1.4847e+00, -1.1046e-01,  8.9979e-01, -1.9165e+00, -4.4945e-01,\n          -2.9848e-01, -1.5685e+00,  4.3572e-01,  1.4080e-01, -1.3210e+00,\n          -7.1064e-01,  5.6128e-01,  8.8877e-01,  9.6616e-01, -7.2182e-01,\n           1.5497e+00,  1.2478e+00, -2.7926e-01,  2.3774e+00,  4.6843e-01,\n           8.2842e-01, -5.0900e-01,  4.3904e-01,  9.3011e-03,  5.6372e-01,\n          -6.7623e-01, -1.3174e+00, -3.3618e-01, -8.5175e-01,  1.7084e+00,\n           3.9251e-01,  6.1506e-01,  1.6341e+00, -2.7244e-02,  1.0603e+00,\n           6.2143e-01,  1.8539e+00,  8.0723e-01,  7.0309e-01,  6.7047e-01,\n           2.0411e-01, -5.3258e-01, -1.4166e+00,  6.0213e-01, -1.0231e+00,\n          -1.7525e+00,  2.0353e+00, -5.4666e-01,  1.4422e+00, -3.2823e-01,\n          -1.1709e+00,  8.1312e-01,  3.5337e-01, -8.8316e-01, -1.2471e+00,\n          -1.9352e-01,  5.1235e-01, -8.0290e-01, -6.0411e-01,  4.7489e-02,\n          -3.0681e-01, -8.0887e-01, -1.2147e+00,  1.2481e+00, -1.6954e+00,\n           1.7670e-01, -6.9225e-01,  7.1540e-02,  2.0898e+00,  1.1484e-01,\n          -8.2643e-01,  8.3625e-02,  1.1815e+00, -4.9900e-01,  9.8698e-02,\n          -7.1430e-01,  1.7285e+00,  1.4402e+00, -3.2650e-03, -1.4089e-01,\n          -1.3567e+00, -9.2281e-02,  3.2848e-01, -1.7771e-01, -2.0604e-01,\n           1.4197e+00, -4.3751e-01, -3.2615e-01,  6.2895e-01,  5.3981e-01]],\n\n        [[ 1.6892e+00, -1.9431e-01, -3.2224e-01,  3.4490e-01, -1.1653e+00,\n          -3.9481e-01, -3.5266e-01,  5.9497e-01,  2.1040e+00, -1.6459e+00,\n          -9.0557e-01, -1.1838e+00, -6.3269e-01, -9.6686e-01, -1.1722e+00,\n           5.4055e-01, -2.9333e-01,  1.9952e+00, -1.3771e-01,  2.9921e+00,\n          -6.5558e-01, -9.3074e-01, -2.2860e-01, -2.2551e-02,  9.0229e-01,\n          -2.0580e-03, -7.8316e-01, -8.9419e-01, -2.2447e-01, -1.8828e+00,\n           1.0121e+00,  1.3446e+00, -4.9502e-01, -3.0010e-01, -5.9109e-01,\n          -1.4185e-01,  5.4657e-02, -6.8540e-01,  6.5147e-02,  2.9379e+00,\n          -4.9744e-01, -1.7516e+00, -2.7392e-01,  1.7361e+00,  2.5768e-01,\n           8.0858e-01, -7.7159e-01, -1.6262e+00, -1.6733e+00, -2.0280e-01,\n          -4.3399e-01,  2.9403e-01,  4.1337e-01,  1.4134e+00,  1.7226e+00,\n          -8.6325e-01,  1.0139e+00,  1.3789e-01, -1.9410e-01,  5.0410e-01,\n          -9.0640e-01, -1.4849e+00,  4.1672e-02, -1.7339e-01,  7.6474e-01,\n          -6.8545e-01, -8.4875e-01, -6.3901e-01, -1.9897e+00,  9.4109e-02,\n          -1.0168e+00, -8.8822e-01,  3.0812e-02,  5.4795e-01, -5.3808e-01,\n           3.4739e-01,  1.3666e+00, -7.9314e-02, -5.8982e-03,  8.4411e-01,\n           1.1872e-01, -1.1269e+00, -2.4777e+00,  1.0928e+00,  2.2439e+00,\n          -5.6637e-01,  4.0842e-01, -1.0176e+00,  1.6326e+00, -1.7560e-01,\n           1.1970e-01,  7.9557e-02,  4.5318e-01,  1.2080e+00,  1.6906e+00,\n          -3.1913e+00,  6.5363e-01,  1.0044e+00,  6.5124e-01, -4.6142e-01]],\n\n        [[ 1.1474e+00, -1.2219e+00,  1.5311e+00, -1.9181e+00,  1.0266e+00,\n          -1.0445e+00, -1.5458e-01, -8.7398e-01, -3.9716e-01,  1.2200e+00,\n           5.9102e-01, -2.0237e-01,  2.6036e-01,  2.8829e-01, -6.0330e-01,\n          -2.4380e+00, -1.6508e+00,  6.3733e-01, -8.7281e-01,  9.6396e-01,\n           3.6009e-02,  4.7853e-01,  5.8551e-01, -1.0222e+00,  4.6850e-01,\n           8.5582e-01,  2.3504e-01,  4.0865e-02,  5.8716e-01, -1.5681e+00,\n           1.2935e+00, -2.1845e-01, -2.3343e-02,  5.1217e-01, -1.4539e+00,\n          -1.0669e-01, -1.1420e+00,  7.4076e-01, -6.0516e-01,  9.7153e-01,\n          -1.7203e+00,  1.6090e-01,  7.2770e-01,  1.3474e-01, -2.3276e-01,\n          -9.8349e-01,  8.7394e-01,  1.6044e+00,  2.2305e+00,  1.3159e+00,\n           1.2003e+00,  6.3528e-01,  4.0749e-01,  1.7186e+00,  9.2511e-01,\n          -6.4882e-01, -2.2362e+00, -1.8320e+00,  2.0051e+00,  7.4933e-01,\n          -4.9061e-02, -4.2367e-01, -2.9759e-01, -5.2820e-01, -1.0170e+00,\n           1.9610e+00, -7.1650e-01,  1.2064e+00, -1.3965e+00,  8.5272e-01,\n          -1.1305e+00,  4.8074e-01,  6.8236e-01, -2.9311e-02,  1.4540e+00,\n          -2.0741e+00, -1.4512e+00,  5.4786e-01, -3.1652e-01,  6.1505e-01,\n           8.1605e-01, -3.6835e-01,  1.6427e-01, -1.1652e+00,  5.2819e-01,\n          -9.3690e-01, -1.0042e+00,  2.5815e-01, -2.2093e-01,  1.0568e+00,\n           1.8710e-01, -1.6438e+00, -1.0410e+00, -1.6262e-01,  2.7776e-01,\n          -1.2441e+00,  7.0846e-01, -1.2571e+00, -1.9005e+00, -5.5108e-01]],\n\n        [[-6.2225e-01,  1.1263e-01,  1.5201e+00,  1.6294e+00,  6.9333e-01,\n           1.4749e+00,  4.0515e-01,  1.3435e+00, -1.6834e+00, -1.9123e-01,\n          -2.9999e-01, -1.7239e+00,  3.9591e-01, -1.3796e+00,  1.8547e+00,\n          -1.6333e+00,  1.7782e+00,  2.2036e-01, -1.0546e+00, -3.7253e-01,\n           2.2099e+00, -1.9922e-01, -1.1540e+00,  1.2550e+00, -1.5669e+00,\n          -5.9739e-01, -8.7843e-01,  1.5402e+00,  7.8677e-01,  2.5974e+00,\n           1.7088e+00,  3.4667e-01, -1.3186e+00, -8.7469e-01,  2.6160e+00,\n           1.1151e+00, -2.2571e-01, -5.5196e-01, -3.2358e-01,  6.2215e-02,\n          -5.6477e-01, -9.4670e-01,  9.1513e-03, -1.6173e+00,  4.9922e-01,\n          -1.4955e+00, -9.5343e-01, -1.1535e+00,  3.5272e-01,  6.0270e-01,\n          -3.2133e-01, -5.4476e-01,  1.2251e+00, -1.2561e+00,  1.1752e+00,\n          -8.2474e-01,  6.7103e-01, -1.1552e-01, -8.4066e-01,  1.2818e+00,\n           1.4465e+00,  5.5877e-01,  6.8670e-01, -2.1592e-01, -1.2302e+00,\n          -1.3102e+00,  5.6326e-01,  3.2067e-01, -1.4668e+00,  6.4914e-01,\n           8.9192e-01,  1.1502e+00, -6.2337e-02, -8.9526e-01,  7.5140e-01,\n           9.3156e-01,  8.2075e-01, -2.6678e-01, -1.6224e+00,  1.0034e+00,\n           5.8191e-01, -6.9103e-01, -3.7767e-01,  7.8173e-01, -1.1547e+00,\n           5.6047e-02, -5.8822e-01,  5.8918e-01, -7.3669e-01, -1.3374e+00,\n          -5.9425e-01,  6.1755e-01,  6.9365e-01,  1.0297e+00,  9.5625e-01,\n          -2.8796e-01,  1.7674e-01, -3.5438e-01, -1.3552e+00, -4.5781e-01]]],\n       device='cuda:0')"
     ]
    }
   ],
   "source": [
    "interpret_sentence(lstm_model, 'It was a fantastic performance !', label=1)\n",
    "interpret_sentence(lstm_model, 'Best film ever', label=1)\n",
    "interpret_sentence(lstm_model, 'Such a great show!', label=1)\n",
    "interpret_sentence(lstm_model, 'It was a horrible movie', label=0)\n",
    "interpret_sentence(lstm_model, 'I\\'ve never watched something as bad', label=0)\n",
    "interpret_sentence(lstm_model, 'It is a disgusting movie!', label=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
