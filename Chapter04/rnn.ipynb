{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb0e40e51f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Instructions:\n",
    "\n",
    "- You need to download the dataset from here: https://ai.stanford.edu/~amaas/data/sentiment/\n",
    "- Then, you need to unzip the downloaded zipped file in the present working directory\n",
    "- That should result in a new folder named aclImdb under the present working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 12500/12500 [00:00<00:00, 100451.78it/s]\n",
      "100%|█████████████████████████████████| 12500/12500 [00:00<00:00, 100162.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews : 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read sentiments and reviews data from the text files\n",
    "review_list = []\n",
    "label_list = []\n",
    "for label in ['pos', 'neg']:\n",
    "    for fname in tqdm(os.listdir(f'./aclImdb/train/{label}/')):\n",
    "        if 'txt' not in fname:\n",
    "            continue\n",
    "        with open(os.path.join(f'./aclImdb/train/{label}/', fname), encoding=\"utf8\") as f:\n",
    "            review_list += [f.read()]\n",
    "            label_list += [label]\n",
    "print ('Number of reviews :', len(review_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 25000/25000 [00:00<00:00, 28373.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 334691), ('and', 162228), ('a', 161940), ('of', 145326), ('to', 135042), ('is', 106855), ('in', 93028), ('it', 77099), ('i', 75719), ('this', 75190)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pre-processing review text\n",
    "# to lower\n",
    "review_list = [review.lower() for review in review_list] \n",
    "# remove punctuation\n",
    "review_list = [''.join([letter for letter in review if letter not in punctuation]) for review in tqdm(review_list)] \n",
    "\n",
    "# accumulate all review texts together.\n",
    "reviews_blob = ' '.join(review_list)\n",
    "\n",
    "# generate list of all words of all reviews. create list separated by \",\".\n",
    "# ref(https://note.nkmk.me/python-split-rsplit-splitlines-re/)\n",
    "review_words = reviews_blob.split()\n",
    "\n",
    "# get the word counts\n",
    "# cretate map like; [('a', 5), ('b', 2), ('r', 2)]\n",
    "# [ref](https://docs.python.org/3/library/collections.html#collections.Counter)\n",
    "count_words = Counter(review_words)\n",
    "\n",
    "# sort words as per counts (decreasing order)\n",
    "total_review_words = len(review_words)\n",
    "sorted_review_words = count_words.most_common(total_review_words)\n",
    "\n",
    "print(sorted_review_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1), ('and', 2), ('a', 3), ('of', 4), ('to', 5), ('is', 6), ('in', 7), ('it', 8), ('i', 9), ('this', 10)]\n"
     ]
    }
   ],
   "source": [
    "# create word to integer (token) dictionary in order to encode text as numbers\n",
    "vocab_to_token = {word:idx+1 for idx, (word, count) in enumerate(sorted_review_words)} # throw away count.\n",
    "print(list(vocab_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this was one of the dvds i recently bought in a set of six called frenchfilm to brush up our french before our planned holiday in beautiful provence this year so far as well as improving our french we have considerably enhanced our appreciation of french cinemabr br what a breath of fresh air to the stale predictable unimaginative crash bang wallop drivel being churned out by hollywood what a good example for screenplay writers actors directors and cinematographers to follow it was so stimulating also to see two identifiable characters in the lead roles without them having to be glossy magazine cover figures br br the other thing i liked about this film was the slow character and plot build up which kept you guessing as to how it was all going to end is there any real good in this selfish thug who continually treats his seemingly naïve benefactor with the type of contempt that an excon would display will our sexually frustrated poor little half deaf heroine prove herself to the answer to her dreams and the situation that fate has bestowed upon her the viewer is intrigued by these questions and the actors unravel the answers slowly and convincingly as they face events that challenge and shape their feeling towards each otherbr br once you have seen this film like me you may want to see it again i still have to work out the directors psychological motive for the sub plot in the role of the parole officer and some of the subtle nuances of camera work are worth a second look the plot does ask for a little imagination when our hero is given a chance to assist our misused and overworked heroine in the office you must also be broad minded to believe in her brilliant lip reading and how some of the action falls into place but if you go along for the thrilling ride with this example of french cinema at its best you will come out more than satisfied four stars out of five for me\n",
      "\n",
      "[10, 13, 28, 4, 1, 3586, 9, 1002, 1199, 7, 3, 272, 4, 1533, 482, 57550, 5, 8540, 57, 253, 782, 155, 253, 4287, 3148, 7, 299, 43770, 10, 335, 37, 233, 14, 73, 14, 11996, 253, 782, 71, 25, 5706, 6420, 253, 4751, 4, 782, 6710, 12, 48, 3, 2881, 4, 1448, 996, 5, 1, 4883, 723, 6421, 2542, 4706, 15816, 3840, 106, 14098, 45, 32, 354, 48, 3, 49, 453, 15, 873, 857, 151, 659, 2, 18053, 5, 838, 8, 13, 37, 9666, 78, 5, 67, 104, 16479, 101, 7, 1, 479, 555, 200, 97, 251, 5, 27, 7988, 3367, 1097, 2529, 12, 12, 1, 80, 150, 9, 404, 42, 10, 19, 13, 1, 593, 108, 2, 113, 1719, 57, 59, 792, 22, 3057, 14, 5, 86, 8, 13, 31, 165, 5, 128, 6, 47, 98, 145, 49, 7, 10, 3878, 8700, 36, 5823, 4325, 24, 1502, 13147, 24234, 16, 1, 583, 4, 6090, 11, 33, 10310, 58, 2396, 76, 253, 3352, 3486, 329, 110, 356, 5356, 1896, 1872, 754, 5, 1, 1462, 5, 39, 1264, 2, 1, 902, 11, 1933, 43, 21183, 719, 39, 1, 506, 6, 3645, 32, 127, 1185, 2, 1, 151, 8386, 1, 2801, 1301, 2, 4575, 14, 34, 401, 672, 11, 2852, 2, 3100, 64, 530, 911, 247, 5085, 12, 271, 22, 25, 107, 10, 19, 38, 69, 22, 193, 177, 5, 67, 8, 172, 9, 123, 25, 5, 160, 45, 1, 659, 1873, 6091, 15, 1, 4576, 113, 7, 1, 213, 4, 1, 11997, 1858, 2, 46, 4, 1, 1265, 6906, 4, 384, 160, 23, 276, 3, 325, 162, 1, 113, 120, 912, 15, 3, 110, 1519, 50, 253, 664, 6, 334, 3, 566, 5, 9441, 253, 16480, 2, 18054, 1896, 7, 1, 1062, 22, 216, 78, 27, 3841, 5460, 5, 255, 7, 39, 524, 7200, 876, 2, 86, 46, 4, 1, 215, 706, 77, 268, 18, 44, 22, 137, 353, 15, 1, 3040, 1353, 16, 10, 453, 4, 782, 442, 30, 29, 114, 22, 76, 208, 45, 51, 70, 4354, 707, 389, 45, 4, 710, 15, 69]\n"
     ]
    }
   ],
   "source": [
    "reviews_tokenized = []\n",
    "for review in review_list:\n",
    "    word_to_token = [vocab_to_token[word] for word in review.split()]\n",
    "    reviews_tokenized.append(word_to_token)\n",
    "print(review_list[0])\n",
    "print()\n",
    "print (reviews_tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode sentiments as 0 or 1\n",
    "encoded_label_list = [1 if label =='pos' else 0 for label in label_list]\n",
    "\n",
    "# length of each reviews \n",
    "reviews_len = [len(review) for review in reviews_tokenized]\n",
    "\n",
    "# delete empty reviews\n",
    "reviews_tokenized = [reviews_tokenized[i] for i, l in enumerate(reviews_len) if l>0 ]\n",
    "\n",
    "# let encoded label list to numpy array. \n",
    "encoded_label_list = np.array([encoded_label_list[i] for i, l in enumerate(reviews_len) if l> 0 ], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def pad_sequence(reviews_tokenized, sequence_length):\n",
    "    ''' returns the tokenized review sequences padded with 0's or truncated to the sequence_length.\n",
    "    '''\n",
    "    # create initial all 0 reviews\n",
    "    padded_reviews = np.zeros((len(reviews_tokenized), sequence_length), dtype = int)\n",
    "    \n",
    "    for idx, review in enumerate(reviews_tokenized):\n",
    "        review_len = len(review)\n",
    "        \n",
    "        if review_len <= sequence_length:\n",
    "            zeroes = list(np.zeros(sequence_length-review_len))\n",
    "            new_sequence = zeroes+review # add 0s to a head.\n",
    "        elif review_len > sequence_length:\n",
    "            new_sequence = review[0:sequence_length] # cut.\n",
    "        \n",
    "        padded_reviews[idx,:] = np.array(new_sequence)\n",
    "    \n",
    "    return padded_reviews\n",
    "\n",
    "sequence_length = 512\n",
    "padded_reviews = pad_sequence(reviews_tokenized=reviews_tokenized, sequence_length=sequence_length)\n",
    "\n",
    "plt.hist(reviews_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation.\n",
    "train_val_split = 0.75\n",
    "train_X = padded_reviews[:int(train_val_split*len(padded_reviews))]\n",
    "train_y = encoded_label_list[:int(train_val_split*len(padded_reviews))]\n",
    "validation_X = padded_reviews[int(train_val_split*len(padded_reviews)):]\n",
    "validation_y = encoded_label_list[int(train_val_split*len(padded_reviews)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If while training, you get a runtime error that says: \"RuntimeError: Expected tensor for argument #1 'indices' to have scalar type Long\".\n",
    "## simply uncomment run the following lines of code additionally\n",
    "# train_X = train_X.astype('int64')\n",
    "# train_y = train_y.astype('int64')\n",
    "# validation_X = validation_X.astype('int64')\n",
    "# validation_y = validation_y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate torch datasets\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_X).to(device), torch.from_numpy(train_y).to(device))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(validation_X).to(device), torch.from_numpy(validation_y).to(device))\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "# torch dataloaders (shuffle data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input size:  torch.Size([32, 512])\n",
      "Example Input:\n",
      " tensor([[    0,     0,     0,  ...,   293,   781,   252],\n",
      "        [    0,     0,     0,  ...,   103,    10,   585],\n",
      "        [    0,     0,     0,  ...,     7,    55,  2258],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,    45,     4,   301],\n",
      "        [    0,     0,     0,  ...,     3,   124,   688],\n",
      "        [    0,     0,     0,  ..., 60696,    12,  1947]], device='cuda:0')\n",
      "\n",
      "Example Output size:  torch.Size([32])\n",
      "Example Output:\n",
      " tensor([1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# get a batch of train data\n",
    "train_data_iter = iter(train_dataloader)\n",
    "X_example, y_example = train_data_iter.next()\n",
    "print('Example Input size: ', X_example.size()) # batch_size, seq_length\n",
    "print('Example Input:\\n', X_example)\n",
    "print()\n",
    "print('Example Output size: ', y_example.size()) # batch_size\n",
    "print('Example Output:\\n', y_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dimension, embedding_dimension, hidden_dimension, output_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(input_dimension, embedding_dimension)  \n",
    "        self.rnn_layer = nn.RNN(embedding_dimension, hidden_dimension, num_layers=1)\n",
    "        self.fc_layer = nn.Linear(hidden_dimension, output_dimension)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        # sequence shape = (sequence_length, batch_size)\n",
    "        embedding = self.embedding_layer(sequence)  \n",
    "        # embedding shape = [sequence_length, batch_size, embedding_dimension]\n",
    "        output, hidden_state = self.rnn_layer(embedding)\n",
    "        # output shape = [sequence_length, batch_size, hidden_dimension]\n",
    "        # hidden_state shape = [1, batch_size, hidden_dimension] (1 for normal RNN, 2 for bidirectional RNN.)\n",
    "        final_output = self.fc_layer(hidden_state[-1,:,:].squeeze(0)) # squeeze first(0) dim=uni directional. ref: https://pytorch.org/docs/stable/generated/torch.squeeze.html#torch.squeeze\n",
    "        return final_output\n",
    "    \n",
    "input_dimension = len(vocab_to_token)+1 # +1 to account for padding 0. vocab_to_token = [('the', 1), ('and', 2),...]\n",
    "embedding_dimension = 100 # embed feature dim.\n",
    "hidden_dimension = 32\n",
    "output_dimension = 1 # positive or negative.\n",
    "\n",
    "rnn_model = RNN(input_dimension, embedding_dimension, hidden_dimension, output_dimension)\n",
    "\n",
    "optim = torch.optim.Adam(rnn_model.parameters())\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "\n",
    "rnn_model = rnn_model.to(device)\n",
    "loss_func = loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns 0-1 accuracy for the given set of predictions and ground truth\n",
    "    \"\"\"\n",
    "    # round predictions to either 0 or 1\n",
    "    rounded_predictions = torch.round(torch.sigmoid(predictions))\n",
    "    success = (rounded_predictions == ground_truth).float() #convert into float for division \n",
    "    accuracy = success.sum() / len(success)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.train()\n",
    "    \n",
    "    for sequence, sentiment in dataloader: # sentiment means ground truth sentiment.\n",
    "        optim.zero_grad()     \n",
    "        preds = model(sequence.T).squeeze()\n",
    "        \n",
    "        loss_curr = loss_func(preds, sentiment) # loss_func = nn.BCEWithLogitsLoss()\n",
    "        accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "        \n",
    "        loss_curr.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss += loss_curr.item()\n",
    "        accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, loss_func):\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequence, sentiment in dataloader:\n",
    "            \n",
    "            preds = model(sequence.T).squeeze()\n",
    "            \n",
    "            loss_curr = loss_func(preds, sentiment)   \n",
    "            accuracy_curr = accuracy_metric(preds, sentiment)\n",
    "            \n",
    "            # no backward.() and optim.step().\n",
    "\n",
    "            loss += loss_curr.item()\n",
    "            accuracy += accuracy_curr.item()\n",
    "        \n",
    "    return loss/len(dataloader), accuracy/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1 | time elapsed: 7.949818134307861s\n",
      "training loss: 0.622 | training accuracy: 66.34%\n",
      "validation loss: 1.056 |  validation accuracy: 21.50%\n",
      "\n",
      "epoch number: 2 | time elapsed: 7.81295108795166s\n",
      "training loss: 0.523 | training accuracy: 74.29%\n",
      "validation loss: 0.999 |  validation accuracy: 38.99%\n",
      "\n",
      "epoch number: 3 | time elapsed: 7.674136638641357s\n",
      "training loss: 0.437 | training accuracy: 80.13%\n",
      "validation loss: 0.769 |  validation accuracy: 60.47%\n",
      "\n",
      "epoch number: 4 | time elapsed: 7.675785064697266s\n",
      "training loss: 0.360 | training accuracy: 84.67%\n",
      "validation loss: 0.963 |  validation accuracy: 56.90%\n",
      "\n",
      "epoch number: 5 | time elapsed: 7.681114196777344s\n",
      "training loss: 0.284 | training accuracy: 88.86%\n",
      "validation loss: 0.686 |  validation accuracy: 72.81%\n",
      "\n",
      "epoch number: 6 | time elapsed: 7.688571214675903s\n",
      "training loss: 0.224 | training accuracy: 91.62%\n",
      "validation loss: 0.924 |  validation accuracy: 64.83%\n",
      "\n",
      "epoch number: 7 | time elapsed: 7.689738988876343s\n",
      "training loss: 0.270 | training accuracy: 88.60%\n",
      "validation loss: 1.046 |  validation accuracy: 50.48%\n",
      "\n",
      "epoch number: 8 | time elapsed: 7.706131935119629s\n",
      "training loss: 0.219 | training accuracy: 91.47%\n",
      "validation loss: 1.040 |  validation accuracy: 65.99%\n",
      "\n",
      "epoch number: 9 | time elapsed: 7.724797964096069s\n",
      "training loss: 0.135 | training accuracy: 95.39%\n",
      "validation loss: 1.018 |  validation accuracy: 66.90%\n",
      "\n",
      "epoch number: 10 | time elapsed: 7.684845209121704s\n",
      "training loss: 0.110 | training accuracy: 96.46%\n",
      "validation loss: 1.132 |  validation accuracy: 67.86%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    time_start = time.time()\n",
    "    \n",
    "    training_loss, train_accuracy = train(rnn_model, train_dataloader, optim, loss_func)\n",
    "    validation_loss, validation_accuracy = validate(rnn_model, validation_dataloader, loss_func)\n",
    "    \n",
    "    time_end = time.time()\n",
    "    time_delta = time_end - time_start  \n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        torch.save(rnn_model.state_dict(), 'rnn_model.pt')\n",
    "    \n",
    "    print(f'epoch number: {ep+1} | time elapsed: {time_delta}s')\n",
    "    print(f'training loss: {training_loss:.3f} | training accuracy: {train_accuracy*100:.2f}%')\n",
    "    print(f'validation loss: {validation_loss:.3f} |  validation accuracy: {validation_accuracy*100:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_inference(model, sentence):\n",
    "    model.eval() # set the model as evaluation mode.\n",
    "    \n",
    "    # text transformations\n",
    "    sentence = sentence.lower()\n",
    "    sentence = ''.join([c for c in sentence if c not in punctuation])\n",
    "    tokenized = [vocab_to_token.get(token, 0) for token in sentence.split()]\n",
    "    # pad with constant value;0. ref: https://numpy.org/doc/stable/reference/generated/numpy.pad.html\n",
    "    tokenized = np.pad(tokenized, (512-len(tokenized), 0), 'constant')\n",
    "    \n",
    "    # model inference\n",
    "    model_input = torch.LongTensor(tokenized).to(device) # 64-bit integer (signed). ref; https://pytorch.org/docs/stable/tensors.html\n",
    "    model_input = model_input.unsqueeze(1) # add batch size 1. ref: https://pytorch.org/docs/stable/generated/torch.unsqueeze.html\n",
    "    pred = torch.sigmoid(model(model_input))\n",
    "    \n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02654528245329857\n",
      "0.535542368888855\n",
      "0.9582849740982056\n",
      "0.9869621992111206\n",
      "0.993883490562439\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_inference(rnn_model, \"This film is horrible\"))\n",
    "print(sentiment_inference(rnn_model, \"Director tried too hard but this film is bad\"))\n",
    "print(sentiment_inference(rnn_model, \"Decent movie, although could be shorter\"))\n",
    "print(sentiment_inference(rnn_model, \"This film will be houseful for weeks\"))\n",
    "print(sentiment_inference(rnn_model, \"I loved the movie, every part of it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
